{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Reads Choice Award Books Web Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prototyping using BeautifulSoup and requests for webscraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out the initial web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.goodreads.com/book/show/39863520-how-to-date-men-when-you-hate-men'\n",
    "page = urllib.request.urlopen(link)\n",
    "\n",
    "soup = bs(page, 'html.parser')\n",
    "\n",
    "#soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>How to Date Men When You Hate Men by Blythe Roberson</title>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of URLs for 15 comments about a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url = 'https://www.goodreads.com/book/reviews/39863520-how-to-date-men-when-you-hate-men?rating=&text_only=true'\n",
    "# r = requests.get(url).content\n",
    "# prefix = 'https://www.goodreads.com/review/show/'\n",
    "# [prefix + x.split('\\\\')[0] for x in str(r).split(prefix)][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get URLs for the top books 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We started by getting the url for every genre category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.goodreads.com/choiceawards/best-fiction-books-2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = urllib.request.urlopen(url)\n",
    "soup = bs(r, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this extracts the url for every genre category of 2019 choice awards\n",
    "soup.find_all('a', {'class':'categoriesList__categoryLink categoriesList__categoryLink--current'})\n",
    "every_genre_list = []\n",
    "for a in soup.find_all('a',{'class':\"categoriesList__categoryLink categoriesList__categoryLink--current\"},  href=True):\n",
    "    every_genre_list.append('https://www.goodreads.com' + (a['href']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.goodreads.com/choiceawards/best-mystery-thriller-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-historical-fiction-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-fantasy-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-romance-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-science-fiction-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-horror-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-humor-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-nonfiction-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-memoir-autobiography-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-history-biography-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-science-technology-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-food-cookbooks-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-graphic-novels-comics-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-poetry-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-debut-novel-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-young-adult-fiction-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-young-adult-fantasy-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-childrens-books-2019',\n",
       " 'https://www.goodreads.com/choiceawards/best-picture-books-2019']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every_genre_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then we get the urls for every book in all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:58<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# # Run this code to retrieve all good r\n",
    "# book_list_2019 = []\n",
    "# for i in tqdm(every_genre_list):\n",
    "#     url = i\n",
    "#     r = urllib.request.urlopen(url)\n",
    "#     soup = bs(r, 'html.parser')\n",
    "#     for a in soup.find_all('a',{\"class\":\"pollAnswer__bookLink\"},  href=True):\n",
    "#         book_list_2019.append('https://www.goodreads.com' + (a['href']))\n",
    "# df = pd.DataFrame(book_list_2019)\n",
    "# book_list_2019 = df.to_csv('book_list_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list_2019 = pd.read_csv('book_list_2019').drop('Unnamed: 0', axis=1)\n",
    "# this is all urls for the best books of 2019\n",
    "len(book_list_2019) # 380\n",
    "book_list_2019 = book_list_2019.squeeze().tolist() # turn CSV back into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Relevant Data from Choice Award books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions to retrieve dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'November 20th 2018'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_date(soup):\n",
    "    link = soup\n",
    "    page = urllib.request.urlopen(link)\n",
    "    soup = bs(page, \"html.parser\")\n",
    "    get_date = soup.find('div', {'id':\"details\"})\n",
    "    get_date = get_date.contents[3].get_text()\n",
    "    get_date = get_date.replace('\\n', '')\n",
    "    get_date = re.findall(r'((?<=Published        ).+\\b)(\\d{4})', get_date)[0]\n",
    "#     get_date = re.find\n",
    "    get_date = get_date[0].rstrip() + ', ' + get_date[1]\n",
    "    get_date = get_date.rsplit('by', 2)[0].rstrip() # gets rid of extra text after published date\n",
    "\n",
    "#     all(r'((?<=Published        ).+\\b)(\\d{4})', get_date)[0]\n",
    "    return get_date\n",
    "def get_month_day(soup):\n",
    "    get_month_day = get_date(soup)[0]\n",
    "    return get_month_day\n",
    "def get_month(soup):\n",
    "    get_month = get_date(soup)[0].split(' ')[0]\n",
    "    return get_month\n",
    "def get_year(soup):\n",
    "    get_year = get_date(soup)[1]\n",
    "    return get_year\n",
    "\n",
    "get_date(book_list_2019[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all book details using this function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(book_links):\n",
    "    book_info = []\n",
    "    for url in tqdm(book_links):\n",
    "        r = requests.get(url)\n",
    "        soup = bs(r.text)\n",
    "        get_descrip = soup.find('div', {'id':\"description\"})\n",
    "        div = soup.find('div', id='description')\n",
    "        description = div.text\n",
    "        description = description[1:-9]\n",
    "        \n",
    "        get_title = soup.find('h1',{\"id\":\"bookTitle\"})\n",
    "        get_title = get_title.get_text().replace('\\n', '').replace('  ', '')\n",
    "        \n",
    "        get_genre = soup.find('a', {'class':\"actionLinkLite bookPageGenreLink\"})\n",
    "        get_genre = get_genre.get_text()\n",
    "        \n",
    "        get_rating = soup.find('span',{\"itemprop\":\"ratingValue\"})\n",
    "        get_rating = get_rating.get_text().replace('\\n', '').replace(' ', '')\n",
    "        \n",
    "        get_author = soup.find('span', {'itemprop':\"name\"})\n",
    "        get_author = get_author.get_text()\n",
    "        \n",
    "        get_publisher = soup.find('div', {'id':\"details\"})\n",
    "        get_publisher = get_publisher.contents[3].get_text()\n",
    "        get_publisher = get_publisher.replace('\\n', '')\n",
    "        get_publisher = re.findall(r'(?<=by ).+\\b', get_publisher)[0]\n",
    "        get_publisher = get_publisher.rsplit('(',2)[0].rstrip()\n",
    "        \n",
    "        get_pages = soup.find('span', {'itemprop':\"numberOfPages\"})\n",
    "        get_pages = get_pages.get_text().split(' ')[0]\n",
    "        \n",
    "        get_format = soup.find('span', {'itemprop':\"bookFormat\"})\n",
    "        get_format = get_format.get_text()\n",
    "        \n",
    "        book_info.append({'title': get_title, 'author': get_author, 'description':description, 'genre': get_genre, 'rating': get_rating,\n",
    "           'publisher': get_publisher, 'pages':get_pages, 'format': get_format, 'date': get_date(url)\n",
    "                         ,'url': url})\n",
    "    book_info = pd.DataFrame(book_info)\n",
    "    book_info.to_csv('all_book_info.csv')\n",
    "        \n",
    "    return book_info \n",
    "    \n",
    "\n",
    "# get_description(book_list_2019) # run this code to save a csv file of all book info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
